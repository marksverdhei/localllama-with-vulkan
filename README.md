# localllama-with-vulkan
Use any GPU for LM inferencing!
